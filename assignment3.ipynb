{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home assignment 3\n",
    "\n",
    "You should work on the assignement in groups of 2 participants. \n",
    "\n",
    "Upload your solution as a jupyter notebook to L2P by 17th of July 23:59h. (The deadline is strict)\n",
    "\n",
    "Do not forget to specify the names of all contributing students in the jupyter notebook.\n",
    "\n",
    "You should add comments to your code where necessary and print the relevant results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network representation\n",
    "Given a network obtain representations for the nodes in the jazz network (you can download it from 'http://konect.uni-koblenz.de/networks/arenas-jazz'). The representations are to be obtained the following way. \n",
    "\n",
    "1. Let $Z_u$ and $Z_v$ are the representations of nodes $u$ and $v$. At each step of stochastic gradient descent (SGD) you should randomly select a pair of nodes and minimize the loss function - \n",
    "\n",
    "   $(Z_u^T Z_v - A_{u,v})^2$\n",
    "   \n",
    "2. Obtain another representation of the nodes in the network using the same procedure as in 1 but this time with the loss function as - \n",
    "\n",
    "   $(Z_u^T Z_v - A_{u,v})^2 + (Z_u^T Z_v - A_{u,v}^2)^2$\n",
    "   \n",
    "3. From these two representations obtain the 5-nearest neighbors of node '0'. The distance between two nodes can be measured as the euclidean distance between the representations of the two nodes.\n",
    "\n",
    "\n",
    "  \n",
    "Hints: Calculate the gradient for the loss function and update the representaion vectors using SGD. You can keep the learning rate as 0.001 and the number of iterations as 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.021209130207161e-15, 1.0704289710950333e-15, 1.1312910362709394e-15, 5.813425945625108e-15]\n",
      "[0.0, 1.021209130207161e-15, 1.0704289710950333e-15, 1.1312910362709394e-15, 5.813425945625108e-15]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "learning_rate = 0.001\n",
    "iterations = 5000\n",
    "# constructing graph\n",
    "G = nx.Graph()\n",
    "graph_file = './out.arenas-jazz'\n",
    "if os.path.exists(graph_file):\n",
    "    with open(graph_file) as fs:\n",
    "        try:\n",
    "            for line in fs:\n",
    "                if re.match('%.*', line): #filtering comments out\n",
    "                    continue\n",
    "                else:\n",
    "                    u, v = line.strip().split()\n",
    "                    G.add_edge(u, v)\n",
    "        except:\n",
    "            print('open ' + graph_file +' failed.')\n",
    "else:\n",
    "    print(graph_file + ' is not a correct path.')\n",
    "\n",
    "adj_mat = nx.adjacency_matrix(G)\n",
    "adj_mat = nx.to_numpy_matrix(G)\n",
    "nodes_num = np.shape(adj_mat)[0] # The number of nodes\n",
    "A = adj_mat/(np.sum(adj_mat, 1).reshape(nodes_num, 1)) # Dividing adj matrix by row sum\n",
    "# Assuming these features are considered.\n",
    "# name, sex, age, nationality, height, weight, role\n",
    "representation_dim = 7\n",
    "representations_mat = np.random.rand(representation_dim, nodes_num)\n",
    "\n",
    "# node: representation of a node\n",
    "# dataset: representations of all nodes\n",
    "# num: the number of nearest node\n",
    "def nearest_neighbors(node, dataset, num):\n",
    "    distances = []\n",
    "    for i_node in dataset:\n",
    "        distances.append(np.linalg.norm(node - i_node))\n",
    "    \n",
    "    distances.sort()\n",
    "    return distances[:num]\n",
    "     \n",
    "def loss_basic(R_mat, A_mat):\n",
    "    loss = 0\n",
    "    nodes_num = np.shape(R_mat)[1]\n",
    "    Z_u = np.random.rand(representation_dim, 1)\n",
    "    Z_v = np.random.rand(representation_dim, 1)\n",
    "    for i in range(nodes_num):\n",
    "        Z_u = R_mat[:, i] # column vector\n",
    "        for j in range(nodes_num - i):\n",
    "            Z_v = R_mat[:,j] # column vector\n",
    "            # $(Z_u^T Z_v - A_{u,v})^2$\n",
    "            if i != j:\n",
    "                loss += 2*(np.square(np.dot(Z_u, np.transpose(Z_v)) - A_mat[i,j]))\n",
    "            else:\n",
    "                loss += np.square(np.dot(Z_u, np.transpose(Z_v)) - A_mat[i,j])\n",
    "            \n",
    "    return loss\n",
    "\n",
    "def loss_advance(R_mat, A_mat):\n",
    "    loss = 0\n",
    "    nodes_num = np.shape(R_mat)[1]\n",
    "    Z_u = np.random.rand(representation_dim, 1)\n",
    "    Z_v = np.random.rand(representation_dim, 1)\n",
    "    for i in range(nodes_num):\n",
    "        Z_u = R_mat[i]\n",
    "        for j in range(nodes_num - i):\n",
    "            Z_v = R_mat[j]\n",
    "            #$(Z_u^T Z_v - A_{u,v})^2 + (Z_u^T Z_v - A_{u,v}^2)^2$\n",
    "            Z_uv = np.dot(np.transpose(Z_u), Z_v)\n",
    "            if i != j:\n",
    "                loss += 2*(np.square(Z_uv - A_mat[i,j]) + np.square(Z_uv - np.dot(A_mat[i,j], A_mat[i,j])))\n",
    "            else:\n",
    "                loss += np.square(Z_uv - A_mat[i,j]) + np.square(Z_uv - np.dot(A_mat[i,j], A_mat[i,j]))\n",
    "    return loss\n",
    "        \n",
    "# R_mat: representation matrix\n",
    "# A_mat: adjacency matrix\n",
    "# l_rate: learning rate\n",
    "# m: the number of examples of R_mat, here we are stochastically using 1 example to update gradient.\n",
    "# iterations: the number of iterations\n",
    "# loss_type: 0 - first loss, 1 - second loss\n",
    "def stochatis_gradient_descent(R_mat, A_mat, l_rate, m, iterations, loss_type):\n",
    "    #x_trans = x.transpose()\n",
    "    loss = 0\n",
    "    cost = 0\n",
    "    for i in range(0, iterations):\n",
    "        #print(\"Iteration %d | Cost: %f\" % (i, cost))\n",
    "        # avg gradient\n",
    "        R_mat_trans = np.transpose(R_mat)\n",
    "        random_index = np.random.randint(0, nodes_num, size=2)\n",
    "\n",
    "        #loss = loss_basic(R_mat, A_mat, samples)\n",
    "        Z_u = R_mat[:,random_index[0]]\n",
    "        Z_v = R_mat[:,random_index[1]]\n",
    "        # 1. loss\n",
    "        if loss_type == 0:\n",
    "            loss += 2*(np.square(np.dot(Z_u, np.transpose(Z_v)) - A_mat[random_index[0],random_index[1]]))\n",
    "        # 2. loss\n",
    "        elif loss_type == 1:\n",
    "            Z_uv = np.dot(np.transpose(Z_u), Z_v)\n",
    "            loss += 2*(np.square(Z_uv - A_mat[random_index[0],random_index[1]]) + np.square(Z_uv - np.dot(A_mat[random_index[0],random_index[1]], A_mat[random_index[0],random_index[1]])))\n",
    "        else:\n",
    "            print('Loss type is unknown.')\n",
    "        # avg cost\n",
    "        # cost = np.sum(loss ** 2) / (2 * m)\n",
    "        cost += loss ** 2 / (2 * m)\n",
    "        \n",
    "        representation_trans = R_mat_trans[random_index]\n",
    "        gradient = np.dot(representation_trans, loss) / m\n",
    "        # update weight\n",
    "        R_mat[:,random_index] = R_mat[:,random_index] - l_rate * np.transpose(gradient)\n",
    "       \n",
    "    return R_mat\n",
    "\n",
    "first_result = stochatis_gradient_descent(representations_mat, A, learning_rate, 1, iterations, 0)\n",
    "second_result = stochatis_gradient_descent(representations_mat, A, learning_rate, 1, iterations, 1)\n",
    "print(nearest_neighbors(first_result[0], first_result, 5))\n",
    "print(nearest_neighbors(second_result[0], second_result, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nteract": {
   "version": "0.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
